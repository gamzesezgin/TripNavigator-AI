import requests
import streamlit as st
import json
from typing import Dict, List, Optional
import re
from urllib.parse import quote
import time # Hata durumunda beklemek iÃ§in eklendi

class WikipediaAgent:
    """
    Wikipedia'dan ÅŸehir bilgilerini Ã§eken agent
    """

    def __init__(self):
        self.base_url = "https://tr.wikipedia.org/api/rest_v1/page/summary/"
        self.search_url = "https://tr.wikipedia.org/w/api.php"
        # DÃœZELTME 1: Wikipedia'nÄ±n istediÄŸi User-Agent'Ä± tanÄ±mlÄ±yoruz.
        # Bu, 429 hatasÄ±nÄ± Ã§Ã¶zmek iÃ§in en Ã¶nemli adÄ±mdÄ±r.
        # E-posta veya bir web sitesi linki vermeniz tavsiye edilir.
        self.headers = {
            'User-Agent': 'TravelPlannerApp/1.0 (sizin_emailiniz@example.com)'
        }

    def search_city(self, city_name: str, max_retries: int = 3) -> Optional[Dict]:
        """
        Åehir iÃ§in Wikipedia sayfasÄ± arar ve doÄŸrudan Ã¶zetini getirir.
        Hata durumunda birkaÃ§ kez tekrar dener.
        """
        retries = 0
        while retries < max_retries:
            try:
                # ... (params ve response = requests.get(...) kÄ±smÄ± aynÄ±)
                params = { 'action': 'query', 'format': 'json', 'list': 'search', 'srsearch': city_name, 'srlimit': 1, 'utf8': 1 }
                response = requests.get(self.search_url, params=params, headers=self.headers)
                response.raise_for_status()
                data = response.json()
                
                if 'query' in data and 'search' in data['query'] and data['query']['search']:
                    page_title = data['query']['search'][0]['title']
                    return self.get_summary_by_title(page_title) # BaÅŸarÄ±lÄ± olursa fonksiyondan Ã§Ä±k
                
                return None # SonuÃ§ bulunamazsa Ã§Ä±k
                
            except requests.exceptions.HTTPError as http_err:
                if http_err.response.status_code == 429:
                    retries += 1
                    print(f"!!! HATA (429), deneme {retries}/{max_retries}. 5 saniye bekleniyor...")
                    time.sleep(5)
                else:
                    st.error(f"Wikipedia HTTP hatasÄ±: {http_err}")
                    return None
            except Exception as e:
                st.error(f"Wikipedia arama hatasÄ±: {e}")
                return None
        
        print("Maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±, arama baÅŸarÄ±sÄ±z.")
        return None

    def get_summary_by_title(self, page_title: str) -> Optional[Dict]:
        """
        Sayfa baÅŸlÄ±ÄŸÄ± ile Ã¶zet bilgi alÄ±r.
        """
        try:
            url = f"{self.base_url}{quote(page_title)}"
            # DÃœZELTME 1: Her isteÄŸe headers (kimlik bilgisi) ekliyoruz.
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            data = response.json()
            
            return {
                'title': data.get('title', ''),
                'extract': data.get('extract', ''),
                'content_urls': data.get('content_urls', {}),
                'thumbnail': data.get('thumbnail', {}),
                'coordinates': data.get('coordinates', {})
            }
            
        except requests.exceptions.HTTPError as http_err:
            if http_err.response.status_code == 429:
                print(f"!!! Ã–zet alÄ±rken HATA (429): {page_title}. 5 saniye bekleniyor...")
                time.sleep(5) # Wikipedia engellerse 5 saniye bekle ve tekrar dene
                return self.get_summary_by_title(page_title) # Fonksiyonu tekrar Ã§aÄŸÄ±r
            st.error(f"Wikipedia Ã¶zet alma HTTP hatasÄ±: {http_err}")
            return None
        except Exception as e:
            print(f"Wikipedia Ã¶zet alma hatasÄ± ({page_title}): {e}")
            return None

    def get_city_info(self, city_name: str) -> Dict:
        """
        Åehir bilgilerini alÄ±r ve iÅŸler
        """
        # KALDIRILDI: print(f"ğŸ” Wikipedia Agent: '{city_name}' ÅŸehri aranÄ±yor...")
        
        clean_city = self.clean_city_name(city_name)
        
        if not clean_city:
            # KALDIRILDI: print(f"âš ï¸ '{city_name}' temizlenemedi, fallback kullanÄ±lÄ±yor.")
            return self.get_fallback_city_info(city_name)

        wiki_data = self.search_city(clean_city)
        
        if wiki_data:
            processed_info = self.process_city_info(wiki_data, city_name)
            # KALDIRILDI: print(f"âœ… Wikipedia Agent: '{city_name}' bilgileri alÄ±ndÄ±")
            return processed_info
        else:
            fallback_info = self.get_fallback_city_info(city_name)
            # KALDIRILDI: print(f"âš ï¸ Wikipedia Agent: '{clean_city}' iÃ§in sonuÃ§ bulunamadÄ±, fallback bilgi kullanÄ±lÄ±yor")
            return fallback_info
    
    def clean_city_name(self, city_name: str) -> str:
        """
        Åehir adÄ±nÄ± Wikipedia aramasÄ± iÃ§in temizler.
        "AI Ã–nerisi: Ã‡eÅŸme, TÃ¼rkiye" gibi girdileri "Ã‡eÅŸme" haline getirir.
        """
        # DÃœZELTME 2: Temizleme mantÄ±ÄŸÄ±nÄ± iyileÅŸtiriyoruz.
        # "AI Ã–nerisi:" veya benzeri Ã¶n ekleri kaldÄ±r
        if ':' in city_name:
            city_name = city_name.split(':')[-1]
            
        # Ãœlke veya eyalet isimlerini kaldÄ±r (virgÃ¼lden sonrasÄ±nÄ± at)
        city = city_name.split(',')[0]
        
        # BaÅŸtaki ve sondaki boÅŸluklarÄ± temizle
        city = city.strip()
        
        # Gereksiz karakterleri temizle (isteÄŸe baÄŸlÄ±)
        # city = re.sub(r'[^\w\s]', '', city) 
        
        return city
    
    # process_city_info ve get_fallback_city_info fonksiyonlarÄ±nÄ±zda
    # deÄŸiÅŸiklik yapmanÄ±za gerek yok, onlar olduÄŸu gibi kalabilir.
    def process_city_info(self, wiki_data: Dict, original_city: str) -> Dict:
        extract = wiki_data.get('extract', '')
        if len(extract) > 300:
            extract = extract[:300] + "..."
        
        coordinates = wiki_data.get('coordinates', {})
        lat = coordinates.get('lat', 0)
        lon = coordinates.get('lon', 0)
        
        thumbnail = wiki_data.get('thumbnail', {})
        image_url = thumbnail.get('source', '') if thumbnail else ''
        
        return {
            'city_name': original_city,
            'title': wiki_data.get('title', original_city),
            'summary': extract,
            'latitude': lat,
            'longitude': lon,
            'image_url': image_url,
            'wikipedia_url': wiki_data.get('content_urls', {}).get('desktop', {}).get('page', ''),
            'source': 'Wikipedia'
        }
    
    def get_fallback_city_info(self, city_name: str) -> Dict:
        # Bu fonksiyon olduÄŸu gibi kalabilir.
        return {'city_name': city_name, 'title': city_name, 'summary': f"{city_name} hakkÄ±nda bilgi bulunamadÄ±.", 'source': 'General Fallback'}


# Global agent instance
wikipedia_agent = WikipediaAgent()

@st.cache_data
def get_city_wikipedia_info(city_name: str) -> Dict:
    """
    Åehir iÃ§in Wikipedia bilgilerini alÄ±r
    """
    return wikipedia_agent.get_city_info(city_name)